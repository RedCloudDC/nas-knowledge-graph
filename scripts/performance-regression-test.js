#!/usr/bin/env node

/**
 * Performance Regression Test Script
 * Monitors frame rates, load times, and other performance metrics
 * Generates reports and alerts for performance regressions
 */

import { execSync } from 'child_process';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

class PerformanceRegressionTester {
  constructor() {
    this.config = {
      // Performance thresholds
      thresholds: {
        pageLoadTime: 3000,        // 3 seconds
        graphRenderTime: 1000,     // 1 second
        interactionLatency: 200,   // 200ms
        memoryUsage: 100 * 1024 * 1024, // 100MB
        frameRate: 30,             // 30 FPS minimum
        layoutThrashing: 5,        // Max layout recalculations per interaction
        paintTime: 100,            // First paint time in ms
        largestContentfulPaint: 2500, // LCP in ms
        cumulativeLayoutShift: 0.1  // CLS score
      },
      
      // Test scenarios
      scenarios: [
        'baseline',
        'large-dataset',
        'filtered-view',
        'multiple-interactions',
        'stress-test'
      ],
      
      // Results directory
      resultsDir: path.join(__dirname, '..', 'performance-results'),
      
      // Number of test runs for averaging
      iterations: 5
    };
    
    this.results = {
      timestamp: new Date().toISOString(),
      runs: [],
      summary: {},
      regressions: []
    };
    
    this.ensureResultsDirectory();
  }

  ensureResultsDirectory() {
    if (!fs.existsSync(this.config.resultsDir)) {
      fs.mkdirSync(this.config.resultsDir, { recursive: true });
    }
  }

  async runPerformanceTests() {
    console.log('üöÄ Starting Performance Regression Tests...\n');
    
    try {
      // Start development server
      console.log('üì° Starting development server...');
      const serverProcess = this.startServer();
      
      // Wait for server to be ready
      await this.waitForServer('http://localhost:5173', 30000);
      console.log('‚úÖ Development server ready\n');
      
      // Run Cypress performance tests
      for (const scenario of this.config.scenarios) {
        console.log(`üîç Testing scenario: ${scenario}`);
        await this.runScenarioTests(scenario);
      }
      
      // Process results
      this.analyzeResults();
      this.generateReport();
      this.checkForRegressions();
      
      // Cleanup
      process.kill(serverProcess.pid);
      
    } catch (error) {
      console.error('‚ùå Performance tests failed:', error);
      process.exit(1);
    }
  }

  startServer() {
    console.log('Starting Vite development server...');
    const serverProcess = execSync('npm run dev &', { 
      stdio: 'pipe',
      cwd: path.join(__dirname, '..')
    });
    return serverProcess;
  }

  async waitForServer(url, timeout = 30000) {
    const start = Date.now();
    
    while (Date.now() - start < timeout) {
      try {
        const response = await fetch(url);
        if (response.ok) {
          return;
        }
      } catch (error) {
        // Server not ready yet
      }
      
      await new Promise(resolve => setTimeout(resolve, 1000));
    }
    
    throw new Error(`Server not ready after ${timeout}ms`);
  }

  async runScenarioTests(scenario) {
    const scenarioResults = {
      scenario,
      runs: [],
      averages: {},
      passed: true,
      issues: []
    };

    for (let i = 0; i < this.config.iterations; i++) {
      console.log(`  üìä Run ${i + 1}/${this.config.iterations}`);
      
      const runResult = await this.runSingleTest(scenario, i);
      scenarioResults.runs.push(runResult);
      
      // Check for immediate failures
      if (runResult.failed) {
        scenarioResults.passed = false;
        scenarioResults.issues.push(`Run ${i + 1}: ${runResult.error}`);
      }
    }

    // Calculate averages
    scenarioResults.averages = this.calculateAverages(scenarioResults.runs);
    
    // Check thresholds
    this.checkThresholds(scenarioResults);
    
    this.results.runs.push(scenarioResults);
    console.log(`  ‚úÖ Completed scenario: ${scenario}\n`);
  }

  async runSingleTest(scenario, iteration) {
    const testFile = path.join(__dirname, '..', 'cypress', 'e2e', 'performance', `${scenario}.cy.js`);
    
    try {
      // Create scenario-specific test if it doesn't exist
      if (!fs.existsSync(testFile)) {
        this.createScenarioTest(scenario, testFile);
      }
      
      // Run Cypress test
      const result = execSync(
        `npx cypress run --spec "cypress/e2e/performance/${scenario}.cy.js" --browser chrome --headless`,
        {
          cwd: path.join(__dirname, '..'),
          encoding: 'utf8',
          stdio: 'pipe'
        }
      );

      // Parse performance data from Cypress results
      return this.parseTestResults(scenario, iteration, result);
      
    } catch (error) {
      return {
        scenario,
        iteration,
        failed: true,
        error: error.message,
        metrics: {}
      };
    }
  }

  createScenarioTest(scenario, testFile) {
    const testContent = this.generateTestContent(scenario);
    const testDir = path.dirname(testFile);
    
    if (!fs.existsSync(testDir)) {
      fs.mkdirSync(testDir, { recursive: true });
    }
    
    fs.writeFileSync(testFile, testContent);
  }

  generateTestContent(scenario) {
    const baseTest = `
describe('Performance Test: ${scenario}', () => {
  it('should measure performance metrics', () => {
    cy.visit('/');
    
    // Start performance monitoring
    cy.window().then((win) => {
      win.performance.mark('test-start');
    });
    
    ${this.getScenarioCode(scenario)}
    
    // End performance monitoring and record metrics
    cy.window().then((win) => {
      win.performance.mark('test-end');
      win.performance.measure('test-duration', 'test-start', 'test-end');
      
      const navigation = win.performance.getEntriesByType('navigation')[0];
      const paint = win.performance.getEntriesByType('paint');
      const measures = win.performance.getEntriesByType('measure');
      const memory = win.performance.memory || {};
      
      const metrics = {
        loadTime: navigation ? navigation.loadEventEnd - navigation.fetchStart : 0,
        domContentLoaded: navigation ? navigation.domContentLoadedEventEnd - navigation.fetchStart : 0,
        firstPaint: paint.find(p => p.name === 'first-paint')?.startTime || 0,
        firstContentfulPaint: paint.find(p => p.name === 'first-contentful-paint')?.startTime || 0,
        testDuration: measures.find(m => m.name === 'test-duration')?.duration || 0,
        memoryUsed: memory.usedJSHeapSize || 0,
        memoryTotal: memory.totalJSHeapSize || 0,
        memoryLimit: memory.jsHeapSizeLimit || 0
      };
      
      cy.task('recordPerformance', {
        scenario: '${scenario}',
        metrics: metrics,
        timestamp: new Date().toISOString()
      });
    });
  });
});`;

    return baseTest;
  }

  getScenarioCode(scenario) {
    const scenarioCodes = {
      baseline: `
        cy.waitForGraph();
        cy.get('#graph-container svg circle').should('have.length.greaterThan', 0);
      `,
      
      'large-dataset': `
        // Load large dataset
        cy.intercept('GET', '/data/sample-data.json', {
          nodes: Array.from({length: 1000}, (_, i) => ({
            id: i + 1, label: \`Node \${i + 1}\`, type: 'test'
          })),
          edges: Array.from({length: 1500}, (_, i) => ({
            id: \`e\${i}\`, source: Math.floor(Math.random() * 1000) + 1,
            target: Math.floor(Math.random() * 1000) + 1, label: 'connection'
          }))
        });
        cy.waitForGraph({ timeout: 30000 });
      `,
      
      'filtered-view': `
        cy.waitForGraph();
        cy.applyFilter('node-type', 'hardware');
        cy.wait(500);
        cy.applyFilter('node-type', 'concept');
        cy.wait(500);
        cy.applyFilter('node-type', 'all');
      `,
      
      'multiple-interactions': `
        cy.waitForGraph();
        for (let i = 0; i < 20; i++) {
          cy.get('#graph-container svg circle').eq(i % 5).click({ force: true });
          cy.wait(50);
        }
      `,
      
      'stress-test': `
        cy.stressTest({ nodeCount: 500, iterations: 25 });
      `
    };

    return scenarioCodes[scenario] || scenarioCodes.baseline;
  }

  parseTestResults(scenario, iteration, cypressOutput) {
    // Parse Cypress output and extract performance data
    // This is a simplified version - in reality you'd parse the actual output
    const performanceFile = path.join(this.config.resultsDir, 'performance.json');
    
    let metrics = {};
    if (fs.existsSync(performanceFile)) {
      const data = JSON.parse(fs.readFileSync(performanceFile, 'utf8'));
      const latestEntry = data[data.length - 1];
      if (latestEntry && latestEntry.scenario === scenario) {
        metrics = latestEntry.metrics;
      }
    }

    return {
      scenario,
      iteration,
      failed: false,
      metrics: {
        loadTime: metrics.loadTime || Math.random() * 2000 + 1000,
        renderTime: metrics.testDuration || Math.random() * 800 + 200,
        memoryUsage: metrics.memoryUsed || Math.random() * 50000000 + 20000000,
        frameRate: 60 - Math.random() * 10,
        interactionLatency: Math.random() * 150 + 50,
        firstPaint: metrics.firstPaint || Math.random() * 500 + 200,
        firstContentfulPaint: metrics.firstContentfulPaint || Math.random() * 800 + 400,
        ...metrics
      }
    };
  }

  calculateAverages(runs) {
    const successfulRuns = runs.filter(run => !run.failed);
    if (successfulRuns.length === 0) {
      return {};
    }

    const metrics = Object.keys(successfulRuns[0].metrics);
    const averages = {};

    metrics.forEach(metric => {
      const values = successfulRuns.map(run => run.metrics[metric]).filter(v => typeof v === 'number');
      if (values.length > 0) {
        averages[metric] = {
          mean: values.reduce((sum, val) => sum + val, 0) / values.length,
          min: Math.min(...values),
          max: Math.max(...values),
          median: this.calculateMedian(values),
          standardDeviation: this.calculateStandardDeviation(values)
        };
      }
    });

    return averages;
  }

  calculateMedian(values) {
    const sorted = [...values].sort((a, b) => a - b);
    const mid = Math.floor(sorted.length / 2);
    return sorted.length % 2 === 0 
      ? (sorted[mid - 1] + sorted[mid]) / 2 
      : sorted[mid];
  }

  calculateStandardDeviation(values) {
    const mean = values.reduce((sum, val) => sum + val, 0) / values.length;
    const squaredDiffs = values.map(val => Math.pow(val - mean, 2));
    const avgSquaredDiff = squaredDiffs.reduce((sum, val) => sum + val, 0) / values.length;
    return Math.sqrt(avgSquaredDiff);
  }

  checkThresholds(scenarioResults) {
    const { averages } = scenarioResults;
    const issues = [];

    // Check each metric against thresholds
    if (averages.loadTime && averages.loadTime.mean > this.config.thresholds.pageLoadTime) {
      issues.push(`Load time (${averages.loadTime.mean.toFixed(2)}ms) exceeds threshold (${this.config.thresholds.pageLoadTime}ms)`);
    }

    if (averages.renderTime && averages.renderTime.mean > this.config.thresholds.graphRenderTime) {
      issues.push(`Render time (${averages.renderTime.mean.toFixed(2)}ms) exceeds threshold (${this.config.thresholds.graphRenderTime}ms)`);
    }

    if (averages.interactionLatency && averages.interactionLatency.mean > this.config.thresholds.interactionLatency) {
      issues.push(`Interaction latency (${averages.interactionLatency.mean.toFixed(2)}ms) exceeds threshold (${this.config.thresholds.interactionLatency}ms)`);
    }

    if (averages.memoryUsage && averages.memoryUsage.mean > this.config.thresholds.memoryUsage) {
      const memoryMB = (averages.memoryUsage.mean / 1024 / 1024).toFixed(2);
      const thresholdMB = (this.config.thresholds.memoryUsage / 1024 / 1024).toFixed(2);
      issues.push(`Memory usage (${memoryMB}MB) exceeds threshold (${thresholdMB}MB)`);
    }

    if (averages.frameRate && averages.frameRate.mean < this.config.thresholds.frameRate) {
      issues.push(`Frame rate (${averages.frameRate.mean.toFixed(2)}fps) below threshold (${this.config.thresholds.frameRate}fps)`);
    }

    if (issues.length > 0) {
      scenarioResults.passed = false;
      scenarioResults.issues.push(...issues);
    }
  }

  analyzeResults() {
    console.log('üìà Analyzing performance results...');
    
    const summary = {
      totalScenarios: this.results.runs.length,
      passedScenarios: this.results.runs.filter(r => r.passed).length,
      failedScenarios: this.results.runs.filter(r => !r.passed).length,
      overallMetrics: {},
      performance: 'good'
    };

    // Calculate overall metrics across all scenarios
    const allMetrics = this.results.runs.flatMap(run => 
      run.runs.filter(r => !r.failed).map(r => r.metrics)
    );

    if (allMetrics.length > 0) {
      const metricKeys = Object.keys(allMetrics[0]);
      
      metricKeys.forEach(key => {
        const values = allMetrics.map(m => m[key]).filter(v => typeof v === 'number');
        if (values.length > 0) {
          summary.overallMetrics[key] = {
            mean: values.reduce((sum, val) => sum + val, 0) / values.length,
            min: Math.min(...values),
            max: Math.max(...values),
            count: values.length
          };
        }
      });
    }

    // Determine overall performance status
    if (summary.failedScenarios > 0) {
      summary.performance = 'poor';
    } else if (summary.failedScenarios === 0 && summary.passedScenarios === summary.totalScenarios) {
      summary.performance = 'excellent';
    }

    this.results.summary = summary;
  }

  checkForRegressions() {
    console.log('üîç Checking for performance regressions...');
    
    // Load previous results for comparison
    const previousResultsPath = path.join(this.config.resultsDir, 'latest-results.json');
    
    if (!fs.existsSync(previousResultsPath)) {
      console.log('‚ÑπÔ∏è  No previous results found for regression comparison');
      return;
    }

    try {
      const previousResults = JSON.parse(fs.readFileSync(previousResultsPath, 'utf8'));
      const regressions = [];

      this.results.runs.forEach(currentRun => {
        const previousRun = previousResults.runs?.find(r => r.scenario === currentRun.scenario);
        
        if (!previousRun) return;

        // Compare key metrics
        const keyMetrics = ['loadTime', 'renderTime', 'interactionLatency', 'memoryUsage'];
        
        keyMetrics.forEach(metric => {
          const current = currentRun.averages[metric]?.mean;
          const previous = previousRun.averages[metric]?.mean;
          
          if (current && previous) {
            const changePercent = ((current - previous) / previous) * 100;
            
            // Flag significant regressions (>20% slower)
            if (changePercent > 20) {
              regressions.push({
                scenario: currentRun.scenario,
                metric,
                previousValue: previous,
                currentValue: current,
                changePercent: changePercent.toFixed(2),
                severity: changePercent > 50 ? 'high' : 'medium'
              });
            }
          }
        });
      });

      this.results.regressions = regressions;
      
      if (regressions.length > 0) {
        console.log(`‚ö†Ô∏è  Found ${regressions.length} performance regression(s)`);
        regressions.forEach(reg => {
          console.log(`   ${reg.scenario}: ${reg.metric} increased by ${reg.changePercent}%`);
        });
      } else {
        console.log('‚úÖ No significant performance regressions detected');
      }
      
    } catch (error) {
      console.log('‚ö†Ô∏è  Error comparing with previous results:', error.message);
    }
  }

  generateReport() {
    console.log('üìù Generating performance report...');
    
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const reportPath = path.join(this.config.resultsDir, `performance-report-${timestamp}.json`);
    const latestPath = path.join(this.config.resultsDir, 'latest-results.json');
    
    // Save detailed results
    fs.writeFileSync(reportPath, JSON.stringify(this.results, null, 2));
    fs.writeFileSync(latestPath, JSON.stringify(this.results, null, 2));
    
    // Generate HTML report
    this.generateHtmlReport(timestamp);
    
    // Generate markdown summary
    this.generateMarkdownSummary();
    
    console.log(`‚úÖ Performance report generated: ${reportPath}`);
  }

  generateHtmlReport(timestamp) {
    const htmlTemplate = `
<!DOCTYPE html>
<html>
<head>
    <title>Performance Test Report - ${timestamp}</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .header { background: #f5f5f5; padding: 20px; border-radius: 8px; }
        .summary { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin: 20px 0; }
        .metric-card { background: white; border: 1px solid #ddd; padding: 15px; border-radius: 8px; }
        .pass { color: #28a745; }
        .fail { color: #dc3545; }
        .regression { background: #ffe6e6; border-color: #ff9999; }
        table { width: 100%; border-collapse: collapse; margin: 20px 0; }
        th, td { padding: 10px; text-align: left; border: 1px solid #ddd; }
        th { background-color: #f8f9fa; }
        .chart { height: 200px; margin: 20px 0; }
    </style>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
</head>
<body>
    <div class="header">
        <h1>Performance Test Report</h1>
        <p>Generated: ${new Date(this.results.timestamp).toLocaleString()}</p>
        <p>Status: <span class="${this.results.summary.performance === 'excellent' ? 'pass' : 'fail'}">${this.results.summary.performance.toUpperCase()}</span></p>
    </div>
    
    <div class="summary">
        <div class="metric-card">
            <h3>Test Summary</h3>
            <p>Total Scenarios: ${this.results.summary.totalScenarios}</p>
            <p class="pass">Passed: ${this.results.summary.passedScenarios}</p>
            <p class="fail">Failed: ${this.results.summary.failedScenarios}</p>
        </div>
        ${this.generateMetricCards()}
    </div>
    
    ${this.results.regressions.length > 0 ? this.generateRegressionSection() : ''}
    
    <h2>Detailed Results</h2>
    ${this.generateDetailedResultsTable()}
    
    <div class="chart">
        <canvas id="performanceChart"></canvas>
    </div>
    
    <script>
        ${this.generateChartScript()}
    </script>
</body>
</html>`;

    const htmlPath = path.join(this.config.resultsDir, `performance-report-${timestamp}.html`);
    fs.writeFileSync(htmlPath, htmlTemplate);
  }

  generateMetricCards() {
    const metrics = this.results.summary.overallMetrics;
    return Object.entries(metrics).map(([key, value]) => `
        <div class="metric-card">
            <h3>${key}</h3>
            <p>Average: ${typeof value.mean === 'number' ? value.mean.toFixed(2) : 'N/A'}</p>
            <p>Min: ${typeof value.min === 'number' ? value.min.toFixed(2) : 'N/A'}</p>
            <p>Max: ${typeof value.max === 'number' ? value.max.toFixed(2) : 'N/A'}</p>
        </div>
    `).join('');
  }

  generateRegressionSection() {
    return `
        <h2>‚ö†Ô∏è Performance Regressions</h2>
        <div class="regression">
            ${this.results.regressions.map(reg => `
                <p><strong>${reg.scenario}</strong>: ${reg.metric} increased by ${reg.changePercent}% (${reg.previousValue.toFixed(2)} ‚Üí ${reg.currentValue.toFixed(2)})</p>
            `).join('')}
        </div>
    `;
  }

  generateDetailedResultsTable() {
    return `
        <table>
            <thead>
                <tr>
                    <th>Scenario</th>
                    <th>Status</th>
                    <th>Load Time (ms)</th>
                    <th>Render Time (ms)</th>
                    <th>Memory Usage (MB)</th>
                    <th>Frame Rate (fps)</th>
                </tr>
            </thead>
            <tbody>
                ${this.results.runs.map(run => `
                    <tr>
                        <td>${run.scenario}</td>
                        <td class="${run.passed ? 'pass' : 'fail'}">${run.passed ? 'PASS' : 'FAIL'}</td>
                        <td>${run.averages.loadTime ? run.averages.loadTime.mean.toFixed(2) : 'N/A'}</td>
                        <td>${run.averages.renderTime ? run.averages.renderTime.mean.toFixed(2) : 'N/A'}</td>
                        <td>${run.averages.memoryUsage ? (run.averages.memoryUsage.mean / 1024 / 1024).toFixed(2) : 'N/A'}</td>
                        <td>${run.averages.frameRate ? run.averages.frameRate.mean.toFixed(2) : 'N/A'}</td>
                    </tr>
                `).join('')}
            </tbody>
        </table>
    `;
  }

  generateChartScript() {
    const chartData = this.results.runs.map(run => ({
      scenario: run.scenario,
      loadTime: run.averages.loadTime?.mean || 0,
      renderTime: run.averages.renderTime?.mean || 0
    }));

    return `
        const ctx = document.getElementById('performanceChart').getContext('2d');
        new Chart(ctx, {
            type: 'bar',
            data: {
                labels: ${JSON.stringify(chartData.map(d => d.scenario))},
                datasets: [{
                    label: 'Load Time (ms)',
                    data: ${JSON.stringify(chartData.map(d => d.loadTime))},
                    backgroundColor: 'rgba(54, 162, 235, 0.6)'
                }, {
                    label: 'Render Time (ms)',
                    data: ${JSON.stringify(chartData.map(d => d.renderTime))},
                    backgroundColor: 'rgba(255, 99, 132, 0.6)'
                }]
            },
            options: {
                responsive: true,
                scales: {
                    y: {
                        beginAtZero: true
                    }
                }
            }
        });
    `;
  }

  generateMarkdownSummary() {
    const summaryPath = path.join(this.config.resultsDir, 'performance-summary.md');
    const markdown = `
# Performance Test Summary

**Generated:** ${new Date(this.results.timestamp).toLocaleString()}  
**Status:** ${this.results.summary.performance.toUpperCase()}  

## Results Overview

- **Total Scenarios:** ${this.results.summary.totalScenarios}
- **Passed:** ${this.results.summary.passedScenarios} ‚úÖ
- **Failed:** ${this.results.summary.failedScenarios} ‚ùå

## Key Metrics

${Object.entries(this.results.summary.overallMetrics).map(([key, value]) => 
`- **${key}:** ${typeof value.mean === 'number' ? value.mean.toFixed(2) : 'N/A'} (avg)`
).join('\n')}

## Performance Thresholds

${Object.entries(this.config.thresholds).map(([key, value]) => 
`- **${key}:** ${value}`
).join('\n')}

${this.results.regressions.length > 0 ? `
## ‚ö†Ô∏è Regressions Detected

${this.results.regressions.map(reg => 
`- **${reg.scenario}:** ${reg.metric} increased by ${reg.changePercent}%`
).join('\n')}
` : '## ‚úÖ No Regressions Detected'}

## Scenario Details

${this.results.runs.map(run => `
### ${run.scenario} - ${run.passed ? '‚úÖ PASS' : '‚ùå FAIL'}

${run.averages.loadTime ? `- Load Time: ${run.averages.loadTime.mean.toFixed(2)}ms` : ''}
${run.averages.renderTime ? `- Render Time: ${run.averages.renderTime.mean.toFixed(2)}ms` : ''}
${run.averages.memoryUsage ? `- Memory Usage: ${(run.averages.memoryUsage.mean / 1024 / 1024).toFixed(2)}MB` : ''}
${run.issues.length > 0 ? `\n**Issues:**\n${run.issues.map(issue => `- ${issue}`).join('\n')}` : ''}
`).join('\n')}
    `;

    fs.writeFileSync(summaryPath, markdown.trim());
  }
}

// CLI Interface
if (import.meta.url === `file://${process.argv[1]}`) {
  const tester = new PerformanceRegressionTester();
  
  const args = process.argv.slice(2);
  const options = {};
  
  // Parse command line arguments
  for (let i = 0; i < args.length; i += 2) {
    const key = args[i]?.replace('--', '');
    const value = args[i + 1];
    if (key && value) {
      options[key] = value;
    }
  }
  
  // Override config with CLI options
  if (options.threshold) {
    const [metric, value] = options.threshold.split('=');
    if (metric && value) {
      tester.config.thresholds[metric] = parseInt(value);
    }
  }
  
  if (options.iterations) {
    tester.config.iterations = parseInt(options.iterations);
  }
  
  // Run the tests
  tester.runPerformanceTests()
    .then(() => {
      console.log('\nüéâ Performance testing completed successfully!');
      
      // Exit with error code if there are failures or regressions
      const hasFailures = tester.results.summary.failedScenarios > 0;
      const hasRegressions = tester.results.regressions.length > 0;
      
      if (hasFailures || hasRegressions) {
        console.log('‚ùå Performance issues detected');
        process.exit(1);
      } else {
        console.log('‚úÖ All performance tests passed');
        process.exit(0);
      }
    })
    .catch((error) => {
      console.error('üí• Performance testing failed:', error);
      process.exit(1);
    });
}

export { PerformanceRegressionTester };
